import numpy as np
import pandas as pd
import os
from sklearn.model_selection import train_test_split

os.getcwd()

os.chdir('C:\\Users\\Gagandeep\\Documents')

os.getcwd()

c_train=pd.read_csv("carvan_train.csv")
c_test=pd.read_csv("carvan_test.csv")

c_train.shape

c_test.shape

c_train.isnull().sum().sum()

t1,t2=train_test_split(c_train,test_size=0.20,random_state=42)

X_train=t1.drop(["V86"],1)

y_train=t1["V86"]

X_test=t2.drop(["V86"],1)

y_test=t2["V86"]

from sklearn.linear_model import LogisticRegression
model=LogisticRegression(fit_intercept=True)

params={'penalty':['l1','l2'],
       'C':np.linspace(0.01,100,10),
       'class_weight':['balanced',None]}

from sklearn.model_selection import GridSearchCV

gs=GridSearchCV(model,cv=10,param_grid=params,n_jobs=-1,verbose=5,scoring='roc_auc')

gs.fit(X_train,y_train)

gs.best_estimator_

train_score=gs.best_estimator_.predict_proba(X_train)[:,1]

real=y_train

cutoffs=np.linspace(0.001,0.999,999)

from sklearn.metrics import fbeta_score

fbetas=[]

for cutoff in cutoffs:
    
    predicted=(train_score>cutoff).astype(int)
    
    fbetas.append(fbeta_score(y_train,predicted,2))

my_cutoff=cutoffs[fbetas==max(fbetas)]

predictions=(gs.predict_proba(c_test)[:,1]>my_cutoff).astype(int)

pd.Series(predictions).value_counts()

submissions=pd.DataFrame({'V86':predictions})

submissions.to_csv('Gagandeep_Python_P2_part2.csv',index=False)

